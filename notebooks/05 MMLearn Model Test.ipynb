{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import polars as pl\n",
    "import pickle\n",
    "\n",
    "import lightning as L\n",
    "import toml\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "# nn.Modules\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"../config/model.toml\")\n",
    "targets = toml.load('../config/targets.toml')\n",
    "batch_size = config[\"data\"][\"batch_size\"]\n",
    "n_epochs = config[\"train\"][\"epochs\"]\n",
    "lr = config[\"train\"][\"learning_rate\"]\n",
    "num_workers = config[\"data\"][\"num_workers\"]\n",
    "fusion_method = config[\"model\"][\"fusion_method\"]\n",
    "st_first = config[\"model\"][\"st_first\"] if fusion_method == \"mag\" else True\n",
    "modalities = config[\"data\"][\"modalities\"]\n",
    "with_ts = config[\"model\"][\"with_ts\"]\n",
    "static_only = True if (len(modalities) == 1) and (\"static\" in modalities) else False\n",
    "with_notes = True if \"notes\" in modalities else False\n",
    "outcomes = targets[\"outcomes\"][\"labels\"]\n",
    "outcomes_disp = targets[\"outcomes\"][\"display\"]\n",
    "### Initial setup\n",
    "ids_path = \"../outputs/processed_data\"\n",
    "data_path = \"../outputs/processed_data/mmfair_feat.pkl\"\n",
    "col_path = \"../outputs/processed_data/mmfair_cols.pkl\"\n",
    "outcome = \"in_hosp_death\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_size, n_epochs, lr, num_workers, fusion_method, st_first, modalities, with_ts, static_only, with_notes, outcomes, outcomes_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filepath: str):\n",
    "    \"\"\"Load a pickled object.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to pickle (.pkl) file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Loaded object.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "embeddings = load_pickle(\"../outputs/processed_data/mmfair_feat.pkl\")\n",
    "#emb_new = load_pickle(\"../outputs/prep_data/mmfair_feat.pkl\")\n",
    "cols = load_pickle(\"../outputs/processed_data/mmfair_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = pl.read_csv(os.path.join(ids_path, \"training_ids_\" + outcome + \".csv\")).select(\"subject_id\").to_numpy().flatten()\n",
    "val_ids = pl.read_csv(os.path.join(ids_path, \"validation_ids_\" + outcome + \".csv\")).select(\"subject_id\").to_numpy().flatten()\n",
    "\n",
    "### Downsample train and val data\n",
    "train_ids = train_ids[:5000]\n",
    "val_ids = val_ids[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFn:\n",
    "    \"\"\"Custom collate function for static data and labels.\"\"\"\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        static = torch.stack([data[0] for data in batch])\n",
    "        labels = torch.stack([data[1] for data in batch])\n",
    "\n",
    "        return static, labels\n",
    "\n",
    "\n",
    "class CollateTimeSeries:\n",
    "    \"\"\"Custom collate function that can handle variable-length timeseries in a batch.\"\"\"\n",
    "\n",
    "    def __init__(self, method=\"pack_pad\", min_events=None) -> None:\n",
    "        self.method = method\n",
    "        self.min_events = min_events\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        static = torch.stack([data[0] for data in batch])\n",
    "        labels = torch.stack([data[1] for data in batch])\n",
    "        notes = None\n",
    "        if len(batch[0]) > 3:  # noqa: PLR2004\n",
    "            # pad notes to max length in batch\n",
    "            notes = torch.stack([data[3] for data in batch])\n",
    "            #notes = pad_sequence([data[3] for data in batch], batch_first=True)\n",
    "\n",
    "        # number of dynamic timeseries data (note: dynamic is a list of timeseries)\n",
    "        n_ts = len(batch[0][2])\n",
    "        #print(\"Number of timeseries\", n_ts)\n",
    "\n",
    "        if self.method == \"pack_pad\":\n",
    "            dynamic = []\n",
    "            lengths = []\n",
    "            for ts in range(n_ts):\n",
    "                # Function to pad batch-wise due to timeseries of different lengths\n",
    "                timeseries_lengths = [data[2][ts].shape[0] for data in batch]\n",
    "                #print(\"Timeseries lengths\", timeseries_lengths)\n",
    "                max_events = max(timeseries_lengths)\n",
    "                #print(\"Max events\", max_events)\n",
    "                n_ftrs = batch[0][2][ts].shape[1]\n",
    "                events = torch.zeros((len(batch), max_events, n_ftrs))\n",
    "                for i in range(len(batch)):\n",
    "                    j, k = batch[i][2][ts].shape[0], batch[i][2][ts].shape[1]\n",
    "                    events[i] = torch.concat(\n",
    "                        [batch[i][2][ts], torch.zeros((max_events - j, k))]\n",
    "                    )\n",
    "                dynamic.append(events)\n",
    "                lengths.append(timeseries_lengths)\n",
    "\n",
    "            if notes is not None:\n",
    "                return static, labels, dynamic, lengths, notes\n",
    "            else:\n",
    "                return static, labels, dynamic, lengths\n",
    "\n",
    "        elif self.method == \"truncate\":\n",
    "            # Truncate to minimum num of events in batch/ specified args\n",
    "\n",
    "            dynamic = []\n",
    "            n_ts = len(batch[0][2])\n",
    "            for ts in range(n_ts):\n",
    "                min_events = (\n",
    "                    min([data[2][ts].shape[0] for data in batch])\n",
    "                    if self.min_events is None\n",
    "                    else self.min_events\n",
    "                )\n",
    "                events = [data[2][ts][:min_events] for data in batch]\n",
    "                dynamic.append(events)\n",
    "                \n",
    "            if notes is not None:\n",
    "                return static, labels, dynamic, lengths, notes\n",
    "            else:\n",
    "                return static, labels, dynamic, lengths\n",
    "\n",
    "\n",
    "class MIMIC4Dataset(Dataset):\n",
    "    \"\"\"MIMIC-IV Dataset class. Subclass of Pytorch Dataset.\n",
    "    Reads from .pkl data dictionary where key is patient ID and values are the dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path=None,\n",
    "        col_path=None,\n",
    "        split=None,\n",
    "        ids=None,\n",
    "        static_only=False,\n",
    "        with_notes=False,\n",
    "        outcome=\"in_hosp_death\"\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dict = load_pickle(data_path)\n",
    "        self.col_dict = load_pickle(col_path)\n",
    "        self.id_list = list(self.data_dict.keys()) if ids is None else ids\n",
    "        #print(self.data_dict[self.id_list[0][0]].keys())\n",
    "        self.dynamic_keys = sorted([key for key in self.data_dict[self.id_list[0]].keys() if \"dynamic\" in key])\n",
    "        self.split = split\n",
    "        self.static_only = static_only\n",
    "        self.with_notes = with_notes\n",
    "        self.splits = {\"train\": None, \"val\": None, \"test\": None}\n",
    "        self.outcome = outcome\n",
    "        self.splits[split] = ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return (\n",
    "            len(self.splits[self.split])\n",
    "            if self.split is not None\n",
    "            else len(self.id_list)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pt_id = int(self.splits[self.split][idx])\n",
    "        static = self.data_dict[pt_id][\"static\"]\n",
    "        label = torch.tensor(\n",
    "            self.data_dict[pt_id][self.outcome][0][0], dtype=torch.float32\n",
    "        ).unsqueeze(-1)\n",
    "        static = torch.tensor(static, dtype=torch.float32)\n",
    "\n",
    "        if self.static_only:\n",
    "            return static, label\n",
    "\n",
    "        else:\n",
    "            dynamic = [\n",
    "                self.data_dict[pt_id][i] for i in self.dynamic_keys\n",
    "            ]\n",
    "            dynamic = [torch.tensor(x, dtype=torch.float32) for x in dynamic]\n",
    "            if self.with_notes:\n",
    "                notes = self.data_dict[pt_id][\"notes\"]  # 1 x 768\n",
    "                ### Extract tokens only\n",
    "                emblist = []\n",
    "                for emb in notes:\n",
    "                    emblist.append(emb[1])\n",
    "                    \n",
    "                notes = torch.tensor(emblist, dtype=torch.float32).unsqueeze(0)\n",
    "                notes = torch.nn.functional.pad(notes, (0, 768 - notes.shape[1]))\n",
    "                return static, label, dynamic, notes\n",
    "            else:\n",
    "                return static, label, dynamic\n",
    "\n",
    "    def print_label_dist(self):\n",
    "        # if no particular split then use entire data dict\n",
    "        if self.split is None:\n",
    "            id_list = self.id_list\n",
    "        else:\n",
    "            id_list = self.splits[self.split]\n",
    "\n",
    "        #print(id_list[0], id_list.shape[0], len(id_list[0]))\n",
    "        #print(self.data_dict[id_list[0][0]][self.outcome])\n",
    "        #print(self.data_dict[id_list[0][0]][self.outcome][0][0])\n",
    "\n",
    "        n_positive = len([id_list[i] for i in range(len(id_list)) if self.data_dict[id_list[i]][self.outcome][0][0] == 1])\n",
    "\n",
    "        if self.split is not None:\n",
    "            print(f\"{self.split.upper()}:\")\n",
    "\n",
    "        print(f\"Positive cases: {n_positive}\")\n",
    "        print(\n",
    "            f\"Negative cases: {self.id_list.shape[0] - n_positive}\"\n",
    "        )\n",
    "\n",
    "    def get_feature_dim(self, key=\"static\"):\n",
    "        return self.data_dict[int(self.id_list[0])][key].shape[1]\n",
    "\n",
    "    def get_feature_list(self, key=\"static\"):\n",
    "        return self.col_dict[key + \"_cols\"]\n",
    "\n",
    "    def get_split_ids(self, split):\n",
    "        return self.splits[split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_layers=1, hidden_dim=128, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "        self.project = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        _, (h_T, _) = self.lstm(input_)\n",
    "        output = self.dropout(self.project(h_T[-1]))\n",
    "        return self.relu(output)\n",
    "\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    # Adapted from https://github.com/emnlp-mimic/mimic/blob/main/base.py#L136 inspired by https://arxiv.org/pdf/1908.05787\n",
    "    def __init__(self, inp1_size, inp2_size, inp3_size: int = 0, dropout: int = 0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(inp1_size + inp2_size, 1)\n",
    "        self.fc2 = nn.Linear(inp1_size + inp3_size, 1)\n",
    "        self.fc3 = nn.Linear(inp2_size + inp3_size, inp1_size)\n",
    "        self.beta = nn.Parameter(torch.randn((1,)))\n",
    "        self.norm = nn.LayerNorm(inp1_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inp1, inp2, inp3=None):\n",
    "        w2 = torch.sigmoid(self.fc1(torch.cat([inp1, inp2], -1)))\n",
    "        if inp3 is not None:\n",
    "            w3 = torch.sigmoid(self.fc2(torch.cat([inp1, inp3], -1)))\n",
    "            adjust = self.fc3(torch.cat([w2 * inp2, w3 * inp3], -1))\n",
    "        else:\n",
    "            # only need to adjust input 2\n",
    "            adjust = self.fc3(w2 * inp2)\n",
    "\n",
    "        one = torch.tensor(1).type_as(adjust)\n",
    "        alpha = torch.min(torch.norm(inp1) / torch.norm(adjust) * self.beta, one)\n",
    "        output = inp1 + alpha * adjust\n",
    "        output = self.dropout(self.norm(output)).squeeze()\n",
    "        return output\n",
    "\n",
    "\n",
    "# lightning.LightningModules\n",
    "class MMModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        st_input_dim=18,\n",
    "        st_embed_dim=64,\n",
    "        ts_input_dim=(9, 7),\n",
    "        ts_embed_dim=64,\n",
    "        nt_input_dim=768,\n",
    "        nt_embed_dim=64,\n",
    "        num_layers=1,\n",
    "        dropout=0.1,\n",
    "        num_ts=2,\n",
    "        target_size=1,\n",
    "        lr=0.1,\n",
    "        fusion_method=\"concat\",\n",
    "        st_first=True,\n",
    "        with_ts=False,\n",
    "        with_notes=False,\n",
    "        with_packed_sequences=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_ts = num_ts\n",
    "        self.with_ts = with_ts\n",
    "        self.with_notes = with_notes\n",
    "        self.st_first = st_first\n",
    "        self.fusion_method = fusion_method\n",
    "\n",
    "        self.embed_static = nn.Sequential(\n",
    "            nn.Linear(st_input_dim, st_embed_dim // 2),\n",
    "            nn.LayerNorm(st_embed_dim // 2),\n",
    "            nn.Linear(st_embed_dim // 2, st_embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        if self.with_ts:\n",
    "            #print(ts_input_dim.shape)\n",
    "            #print(ts_input_dim)\n",
    "            #print(ts_embed_dim)\n",
    "            self.embed_timeseries = nn.ModuleList(\n",
    "                [\n",
    "                    LSTM(\n",
    "                        ts_input_dim[i],\n",
    "                        ts_embed_dim,\n",
    "                        num_layers=num_layers,\n",
    "                        dropout=dropout,\n",
    "                    )\n",
    "                    for i in range(self.num_ts)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if self.with_notes:\n",
    "            self.embed_notes = nn.Linear(nt_input_dim, nt_embed_dim)\n",
    "        else:\n",
    "            self.embed_notes = None\n",
    "            nt_embed_dim = 0\n",
    "\n",
    "        if self.fusion_method == \"mag\":\n",
    "            if self.st_first:\n",
    "                self.fuse = Gate(\n",
    "                    st_embed_dim, *([ts_embed_dim] * self.num_ts), dropout=dropout\n",
    "                )\n",
    "                self.fc = nn.Linear(st_embed_dim, target_size)\n",
    "\n",
    "            else:\n",
    "                self.fuse = Gate(\n",
    "                    *([ts_embed_dim] * self.num_ts), st_embed_dim, dropout=dropout\n",
    "                )\n",
    "                self.fc = nn.Linear(ts_embed_dim, target_size)\n",
    "\n",
    "        elif self.fusion_method == \"concat\":\n",
    "            # embeddings must be same dim\n",
    "            assert st_embed_dim == ts_embed_dim\n",
    "            if self.with_notes:\n",
    "                assert nt_embed_dim == st_embed_dim\n",
    "            self.fc = nn.Linear(\n",
    "                st_embed_dim + (self.num_ts * ts_embed_dim) + nt_embed_dim, target_size\n",
    "            )\n",
    "\n",
    "        elif self.fusion_method == \"None\":\n",
    "            self.fc = nn.Linear(st_embed_dim, target_size)\n",
    "\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.lr = lr\n",
    "        self.acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        self.f1 = torchmetrics.F1Score(task=\"binary\")\n",
    "        self.ap = torchmetrics.AveragePrecision(task=\"binary\")\n",
    "\n",
    "        self.with_packed_sequences = with_packed_sequences\n",
    "\n",
    "    def prepare_batch(self, batch):  # noqa: PLR0912\n",
    "        # static, labels, dynamic, lengths, notes (optional) # noqa: E741\n",
    "        s = batch[0]\n",
    "        y = batch[1]\n",
    "\n",
    "        if self.with_ts:\n",
    "            d = batch[2]\n",
    "            if self.with_packed_sequences:\n",
    "                lengths = batch[3]\n",
    "\n",
    "        if self.fusion_method != \"None\":\n",
    "            #print('Packing padded sequences.')\n",
    "            ts_embed = []\n",
    "            for i in range(self.num_ts):\n",
    "                if self.with_packed_sequences:\n",
    "                    packed_d = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "                        d[i], lengths[i], batch_first=True, enforce_sorted=False\n",
    "                    )\n",
    "                    embed = self.embed_timeseries[i](packed_d)\n",
    "                else:\n",
    "                    embed = self.embed_timeseries[i](d[i])\n",
    "\n",
    "                ts_embed.append(embed.unsqueeze(1))\n",
    "\n",
    "        if self.with_notes:\n",
    "            n = batch[4]\n",
    "            nt_embed = self.embed_notes(n)\n",
    "        else:\n",
    "            nt_embed = None\n",
    "\n",
    "        st_embed = self.embed_static(s)\n",
    "\n",
    "        # Fuse time-series and static data\n",
    "        if self.fusion_method == \"concat\":\n",
    "            # use * to allow variable number of ts_embeddings\n",
    "            # concat along feature dim\n",
    "            embeddings = [st_embed, *ts_embed]\n",
    "            embeddings = embeddings + [nt_embed] if nt_embed is not None else embeddings\n",
    "            out = torch.concat(embeddings, dim=-1).squeeze()  # b x dim*2\n",
    "        elif self.fusion_method == \"mag\":\n",
    "            if self.st_first:\n",
    "                out = self.fuse(st_embed, *ts_embed)  # b x st_embed_dim\n",
    "            else:\n",
    "                out = self.fuse(*ts_embed, st_embed)\n",
    "\n",
    "        elif self.fusion_method == \"None\":\n",
    "            # print('No fusion method specified. Using static data only.')\n",
    "            out = st_embed.squeeze()\n",
    "\n",
    "        # Parse through FC\n",
    "        x_hat = self.fc(out)  # b x 1 - logits\n",
    "        if len(x_hat.shape) < 2:  # noqa: PLR2004\n",
    "            x_hat = x_hat.unsqueeze(0)\n",
    "        return x_hat, y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x_hat, y = self.prepare_batch(batch)  # logit\n",
    "        y_hat = torch.sigmoid(x_hat)  # prob\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        accuracy = self.acc(y_hat, y)\n",
    "        auc = self.auc(y_hat, y)\n",
    "        f1 = self.f1(y_hat, y)\n",
    "        ap = self.ap(y_hat, y.long())\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            batch_size=len(y),\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_acc\",\n",
    "            accuracy,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            batch_size=len(y),\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_auc\",\n",
    "            auc,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            batch_size=len(y),\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_f1\",\n",
    "            f1,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            batch_size=len(y),\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_ap\",\n",
    "            ap,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            batch_size=len(y),\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_hat, y = self.prepare_batch(batch)\n",
    "        y_hat = torch.sigmoid(x_hat)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        accuracy = self.acc(y_hat, y)\n",
    "        auc = self.auc(y_hat, y)\n",
    "        f1 = self.f1(y_hat, y)\n",
    "        ap = self.ap(y_hat, y.long())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=len(y))\n",
    "        self.log(\"val_acc\", accuracy, prog_bar=True, batch_size=len(y))\n",
    "        self.log(\"val_auc\", auc, prog_bar=True, batch_size=len(y))\n",
    "        self.log(\"val_f1\", f1, prog_bar=True, batch_size=len(y))\n",
    "        self.log(\"val_ap\", ap, prog_bar=True, batch_size=len(y))\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        x_hat, y = self.prepare_batch(batch)\n",
    "        y_hat = torch.sigmoid(x_hat)\n",
    "        return y_hat, y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=20)\n",
    "        return [optimizer], [\n",
    "            {\"scheduler\": scheduler, \"monitor\": \"val_loss\", \"interval\": \"epoch\"}\n",
    "        ]\n",
    "\n",
    "class LitLSTM(L.LightningModule):\n",
    "    \"\"\"LSTM using time-series data only.\n",
    "\n",
    "    Args:\n",
    "        L (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ts_input_dim,\n",
    "        lstm_embed_dim,\n",
    "        target_size,\n",
    "        lr=0.1,\n",
    "        with_packed_sequences=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_timeseries = LSTM(\n",
    "            ts_input_dim,\n",
    "            lstm_embed_dim,\n",
    "            target_size,\n",
    "            with_packed_sequences=with_packed_sequences,\n",
    "        )\n",
    "        self.fc = nn.Linear(lstm_embed_dim, target_size)\n",
    "\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.lr = lr\n",
    "        self.acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.with_packed_sequences = with_packed_sequences\n",
    "\n",
    "    def prepare_batch(self, batch):\n",
    "        if self.with_packed_sequences:\n",
    "            _, y, d, l = batch  # static, dynamic, lengths, labels  # noqa: E741\n",
    "            d = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "                d, l, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            _, y, d = batch\n",
    "\n",
    "        ts_embed = self.embed_timeseries(d)\n",
    "\n",
    "        # unpack if using packed sequences\n",
    "        if self.with_packed_sequences:\n",
    "            lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "                ts_embed, batch_first=True\n",
    "            )\n",
    "\n",
    "        # [:, -1] for hidden state at the last time step\n",
    "        logits = self.fc(lstm_out[:, -1])\n",
    "        x_hat = F.sigmoid(logits)\n",
    "        return x_hat, y\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x_hat, y = self.prepare_batch(batch)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        accuracy = self.acc(x_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_hat, y = self.prepare_batch(batch)\n",
    "        loss = self.criterion(x_hat, y)\n",
    "        accuracy = self.acc(x_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=len(y))\n",
    "        self.log(\"val_acc\", accuracy, prog_bar=True, batch_size=len(y))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "class SaveLossesCallback(Callback):\n",
    "    def __init__(self, log_dir=\"logs\", save_every_n_epochs=5):\n",
    "        \"\"\"\n",
    "        Callback to save train/validation losses to a CSV file every n epochs.\n",
    "\n",
    "        Args:\n",
    "            log_dir (str): Directory to save the logs.\n",
    "            save_every_n_epochs (int): Interval (in epochs) to save the losses.\n",
    "        \"\"\"\n",
    "        self.log_dir = log_dir\n",
    "        self.save_every_n_epochs = save_every_n_epochs\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        self.csv_file = os.path.join(self.log_dir, \"losses.csv\")\n",
    "\n",
    "        # Initialize the CSV file with headers if it doesn't exist\n",
    "        if not os.path.exists(self.csv_file):\n",
    "            with open(self.csv_file, mode=\"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"Epoch\", \"Train Loss\", \"Validation Loss\"])\n",
    "\n",
    "    def on_train_epoch_end(self, trainer):\n",
    "        # Save losses every n epochs\n",
    "        if (trainer.current_epoch + 1) % self.save_every_n_epochs == 0:\n",
    "            train_loss = trainer.callback_metrics.get(\"train_loss\", None)\n",
    "            val_loss = trainer.callback_metrics.get(\"val_loss\", None)\n",
    "\n",
    "            # Append the losses to the CSV file\n",
    "            with open(self.csv_file, mode=\"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([trainer.current_epoch + 1, train_loss, val_loss])\n",
    "\n",
    "            print(f\"Saved losses to {self.csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(static_only, with_notes, with_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MIMIC4Dataset(\n",
    "        data_path,\n",
    "        col_path,\n",
    "        \"train\",\n",
    "        ids=train_ids,\n",
    "        static_only=static_only,\n",
    "        with_notes=with_notes,\n",
    ")\n",
    "validation_set = MIMIC4Dataset(\n",
    "        data_path,\n",
    "        col_path,\n",
    "        \"val\",\n",
    "        ids=val_ids,\n",
    "        static_only=static_only,\n",
    "        with_notes=with_notes,\n",
    ")\n",
    "training_set.print_label_dist()\n",
    "n_static_features = (\n",
    "        training_set.get_feature_dim()\n",
    ")  # add -1 if dropping label col\n",
    "\n",
    "if not static_only:\n",
    "        n_dynamic_features = (\n",
    "        training_set.get_feature_dim(\"dynamic_0\"),\n",
    "        training_set.get_feature_dim(\"dynamic_1\"),\n",
    "        )\n",
    "        print(n_dynamic_features)\n",
    "        print(n_static_features)\n",
    "        n_val_features = (\n",
    "        validation_set.get_feature_dim(\"static\"),\n",
    "        validation_set.get_feature_dim(\"dynamic_0\"),\n",
    "        validation_set.get_feature_dim(\"dynamic_1\")\n",
    "        )\n",
    "        print(n_val_features)\n",
    "else:\n",
    "        n_dynamic_features = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(training_set))\n",
    "#data = training_set[2]\n",
    "static, label, dynamic, notes = training_set[2]\n",
    "\n",
    "print(\"Static shape:\", static.shape)\n",
    "print(\"Label shape:\", label.shape)\n",
    "for i, ts in enumerate(dynamic):\n",
    "    print(f\"Dynamic modality {i} shape:\", ts.shape)\n",
    "print(\"Notes shape:\", notes.shape)\n",
    "\n",
    "print(notes)\n",
    "print(static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(training_set))\n",
    "#data = training_set[2]\n",
    "static, label, dynamic, notes = validation_set[2]\n",
    "\n",
    "print(\"Static shape:\", static.shape)\n",
    "print(\"Label shape:\", label.shape)\n",
    "for i, ts in enumerate(dynamic):\n",
    "    print(f\"Dynamic modality {i} shape:\", ts.shape)\n",
    "print(\"Notes shape:\", notes.shape)\n",
    "\n",
    "print(notes)\n",
    "print(static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        collate_fn=CollateFn() if static_only else CollateTimeSeries(),\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        collate_fn=CollateFn() if static_only else CollateTimeSeries(),\n",
    ")\n",
    "model = MMModel(\n",
    "        st_input_dim=n_static_features,\n",
    "        ts_input_dim=n_dynamic_features,\n",
    "        with_packed_sequences=True if not static_only else False,\n",
    "        fusion_method=fusion_method,\n",
    "        with_notes=with_notes,\n",
    "        with_ts=with_ts,\n",
    "        st_first=st_first,\n",
    ")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "mod_str = \"_\".join(modalities)\n",
    "checkpoint = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        filename=f\"{outcome}_{fusion_method}_{mod_str}\",\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "#save_losses_callback = SaveLossesCallback(log_dir=f\"logs/{outcome}_{fusion_method}_{mod_str}/\", save_every_n_epochs=5)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "        max_epochs=n_epochs,\n",
    "        accelerator='gpu',\n",
    "        callbacks=[early_stop, checkpoint, lr_monitor],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "        model=model,\n",
    "        train_dataloaders=training_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
