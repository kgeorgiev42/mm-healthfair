{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic overview of generated embedding .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filepath: str):\n",
    "    \"\"\"Load a pickled object.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to pickle (.pkl) file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Loaded object.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def save_pickle(target: dict, filepath: str, fname: str = \"mm_feat.pkl\"):\n",
    "    \"\"\"Save a pickled object from a dictionary.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to pickle (.pkl) file.\n",
    "\n",
    "    Returns:\n",
    "        Any: Loaded object.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(filepath, fname), \"wb\") as f:\n",
    "        pickle.dump(target, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get patient IDs from pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_embs = load_pickle(\"../outputs/prep_data/mmfair_feat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20597"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pt_embs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace EHR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_old = load_pickle(\"../../mm-cp/outputs/processed_data/mmfair_feat.pkl\")\n",
    "embeddings = load_pickle(\"../outputs/prep_data/mmfair_feat.pkl\")\n",
    "cols = load_pickle(\"../outputs/prep_data/mmfair_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [cols['static_cols'].index(col) for col in cols['static_cols'][-14:]]\n",
    "print(indices)\n",
    "print([cols['static_cols'][i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))\n",
    "### Get keys in embeddings but not in embeddings_old\n",
    "keys = set(embeddings.keys()) - set(emb_old.keys())\n",
    "print(len(keys))\n",
    "### Get keys in embeddings_old but not in embeddings\n",
    "keys = set(emb_old.keys()) - set(embeddings.keys())\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_old[10296921]['dynamic_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[10296921]['dynamic_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt_key in embeddings.keys():\n",
    "    embeddings[pt_key]['notes'] = emb_old[pt_key]['notes']\n",
    "    #embeddings[pt_key]['static'] = np.array(embeddings[pt_key]['static']).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correct and export the embeddings\n",
    "save_pickle(embeddings, \"../outputs/prep_data\", \"mmfair_feat.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SHAP values vs embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_pickle(\"../outputs/prep_data/mmfair_feat.pkl\")\n",
    "#emb_old = load_pickle(\"../outputs/prev_data/mmfair_feat.pkl\")\n",
    "cols = load_pickle(\"../outputs/prep_data/mmfair_cols.pkl\")\n",
    "test_ids = (pl.read_csv(os.path.join(\"../outputs/prep_data/testing_ids_ext_stay_7.csv\"))\n",
    "        .select(\"subject_id\")\n",
    "        .to_numpy()\n",
    "        .flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_embeddings = load_pickle(\"../outputs/explanations/ext_stay_7_concat_static_timeseries_notes/shap_ext_stay_7_concat_static_timeseries_notes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP values inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tabluar data\n",
    "for i in range(shap_embeddings['batch_1']['static'].shape[2]):\n",
    "    print(f\"{cols['static_cols'][i]} -> SHAP {shap_embeddings['batch_0']['static'][9][0][i]}; Actual {embeddings[test_ids[9]]['static'][0][i]}\")\n",
    "\n",
    "print(embeddings[test_ids[1]]['static'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare embedding keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embeddings.keys()), len(emb_old.keys()))\n",
    "### Get keys in embeddings but not in embeddings_old\n",
    "keys = set(embeddings.keys()) - set(emb_old.keys())\n",
    "print(len(keys))\n",
    "### Get keys in embeddings_old but not in embeddings\n",
    "keys = set(emb_old.keys()) - set(embeddings.keys())\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict = load_pickle(\"..\\outputs\\evaluation\\ext_stay_7_concat_static_timeseries\\pf_ext_stay_7_concat_static_timeseries.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_dict = load_pickle(\"../outputs/fairness/ext_stay_7_None_timeseries/pf_ext_stay_7_None_timeseries.pkl\")\n",
    "fair_dict_cst = load_pickle(\"../outputs/fairness/ext_stay_7_concat_static_timeseries/pf_ext_stay_7_concat_static_timeseries.pkl\")\n",
    "fair_dict_cstn = load_pickle(\"../outputs/fairness/ext_stay_7_concat_static_timeseries_notes/pf_ext_stay_7_concat_static_timeseries_notes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the keys that start with fair_\n",
    "fair_keys = [key for key in fair_dict.keys() if key.startswith(\"fair_\")]\n",
    "### Select items from the dictionary that start with fair_\n",
    "fair_dict_f = {key: fair_dict[key] for key in fair_keys}\n",
    "fair_dict_cstf = {key: fair_dict_cst[key] for key in fair_keys}\n",
    "fair_dict_cstnf = {key: fair_dict_cstn[key] for key in fair_keys}\n",
    "### Display values within the keys\n",
    "fair_df = pd.concat([pd.DataFrame(fair_dict_f), pd.DataFrame(fair_dict_cstf), pd.DataFrame(fair_dict_cstnf)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(risk_dict['risk_quantile']), len(risk_dict['y_prob']), len(risk_dict['test_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_dict['yd_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recode some of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../outputs/processed_data\", \"mmfair_feat.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_list = []\n",
    "for item in embeddings[id_val]['notes']:\n",
    "    extr_list.append(item[1])\n",
    "print(extr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test training IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hosp_death = pd.read_csv('../outputs/prep_data/training_ids_in_hosp_death.csv')\n",
    "val_hosp_death = pd.read_csv('../outputs/prep_data/validation_ids_in_hosp_death.csv')\n",
    "test_hosp_death = pd.read_csv('../outputs/prep_data/testing_ids_in_hosp_death.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_icu = pd.read_csv('../outputs/prep_data/training_ids_icu_admission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = set(train_icu['subject_id']).intersection(set(train_hosp_death['subject_id']))\n",
    "print(len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ids = list(embeddings.keys())\n",
    "overlap = set(emb_ids).intersection(set(train_hosp_death['subject_id']))\n",
    "overlapv = set(emb_ids).intersection(set(val_hosp_death['subject_id']))\n",
    "overlapt = set(emb_ids).intersection(set(test_hosp_death['subject_id']))\n",
    "print(len(overlap), len(overlapv), len(overlapt), len(train_hosp_death), len(embeddings.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
