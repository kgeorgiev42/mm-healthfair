{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse additional historical features from the EHR (medications, outpatient visits) and time-series data (blood tests, vital signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.dates import DateFormatter\n",
    "from datetime import timedelta, datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy import stats, special\n",
    "from tableone import TableOne\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pprint\n",
    "import missingno as msno\n",
    "from statannotations.Annotator import Annotator\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test parsed metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_data = pd.read_csv('../outputs/ext_data/events_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_data.subject_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = pd.read_csv('../outputs/sample_data/ehr_static.csv')\n",
    "notes_data = pd.read_csv('../outputs/sample_data/notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data.shape, notes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data[['subject_id', 'edregtime', 'edouttime', 'admittime', 'dischtime', \n",
    "             'prev_edregtime', 'prev_dischtime']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data[static_data.edregtime>static_data.prev_dischtime].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load linked demographics data and helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = pd.read_csv('../outputs/linked_data/linked_demographics.csv')\n",
    "print(demo_data.shape, demo_data.subject_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_path = '../../data/MIMIC-IV/mimiciv/3.1'\n",
    "ed_path = '../../data/MIMIC-IV/mimic-iv-ed/3.1'\n",
    "demo_path = '../outputs/linked_data/linked_demographics.csv'\n",
    "ndc_path = '../../data/MIMIC-IV/config/NDC_product_table.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_csv(path, compression='gzip', chunksize=None):\n",
    "    return pd.read_csv(path, compression=compression,\n",
    "                       chunksize=chunksize,\n",
    "                       low_memory=False)\n",
    "\n",
    "########################## MEDICATIONS ##########################\n",
    "def read_prescriptions_table(mimic4_path, demo_path):\n",
    "    meds = dataframe_from_csv(os.path.join(mimic4_path, 'hosp/emar.csv.gz'))\n",
    "    print('Loaded raw administrations table')\n",
    "    linked_demo_data = pd.read_csv(demo_path)\n",
    "    meds = meds.reset_index(drop=True)\n",
    "    print(meds.subject_id.isnull().sum(), meds.shape)\n",
    "    ### Link relevant medications and prepare for parsing\n",
    "    meds = meds[meds.subject_id.isin(linked_demo_data.subject_id)]\n",
    "    print(meds.subject_id.isnull().sum(), meds.shape)\n",
    "    meds['charttime'] = pd.to_datetime(meds.charttime)\n",
    "    meds = pd.merge(meds, linked_demo_data[['subject_id', 'admittime']], \n",
    "                    on='subject_id', how='left')\n",
    "    print(meds.subject_id.isnull().sum(), meds.shape)\n",
    "    meds = meds[meds.charttime <= meds.admittime]\n",
    "    meds = meds.dropna(subset=['medication', 'event_txt'])\n",
    "    print(meds.subject_id.isnull().sum(), meds.shape)\n",
    "    ### Filter correctly administered medications\n",
    "    meds = meds[meds.event_txt.isin(['Administered', 'Confirmed', 'Started'])]\n",
    "    print(meds.subject_id.isnull().sum(), meds.shape)\n",
    "    return meds[['subject_id', 'admittime', 'charttime', 'medication']]\n",
    "\n",
    "def prepare_prescription_features(meds, demo_data, top_threshold=50):\n",
    "    print('Getting prescription features')\n",
    "    meds['medication'] = meds['medication'].str.lower().astype(str).str.strip().str.replace(' ', '_')\n",
    "    meds = meds.sort_values(['subject_id', 'charttime'])\n",
    "    top_meds = meds.medication.value_counts().head(top_threshold).index.tolist()\n",
    "    #### Filter most common medications\n",
    "    meds = meds[meds.medication.isin(top_meds)]\n",
    "    meds['admittime'] = pd.to_datetime(meds['admittime'])\n",
    "    ### Clean some of the top medication fields\n",
    "    meds['medication'] = np.where(meds['medication'].str.contains('vancomycin'), 'vancomycin', meds['medication'])\n",
    "    meds['medication'] = np.where(meds['medication'].str.contains('acetaminophen'), 'acetaminophen', meds['medication'])\n",
    "    meds_ids = meds.groupby(['subject_id', 'medication', 'admittime']).size().reset_index(name='n_presc')\n",
    "    meds_min = meds.groupby(['subject_id', 'medication', 'admittime'])['charttime'].min().reset_index(name='first_date')\n",
    "    meds_min['first_date'] = pd.to_datetime(meds_min['first_date'])\n",
    "    meds_max = meds.groupby(['subject_id', 'medication', 'admittime'])['charttime'].max().reset_index(name='last_date')\n",
    "    meds_max['last_date'] = pd.to_datetime(meds_max['last_date'])\n",
    "    meds_min['dsf'] = (meds_min['admittime'] - meds_min['first_date']).dt.days\n",
    "    meds_max['dsl'] = (meds_max['admittime'] - meds_max['last_date']).dt.days\n",
    "    meds_ids = pd.merge(meds_ids, meds_min[['subject_id', 'medication', 'dsf']], on=['subject_id', 'medication'], how='left')\n",
    "    meds_ids = pd.merge(meds_ids, meds_max[['subject_id', 'medication', 'dsl']], on=['subject_id', 'medication'], how='left')\n",
    "    meds_ids = meds_ids.drop(['admittime'], axis=1)\n",
    "    #### Pivot table and create drug-specific features\n",
    "    def rename(col):\n",
    "        if isinstance(col, tuple):\n",
    "            col = '_'.join(str(c) for c in col)\n",
    "        return col\n",
    "    meds_piv = meds_ids.set_index(['subject_id', 'medication']).unstack()\n",
    "    meds_piv.columns = map(rename, meds_piv)\n",
    "    meds_piv = meds_piv.reset_index()\n",
    "    meds_piv_total = meds_ids.groupby(['subject_id'])['medication'].nunique().reset_index(name='total_n_presc')\n",
    "    demo_data = pd.merge(demo_data, meds_piv_total, on='subject_id', how='left')\n",
    "    demo_data = pd.merge(demo_data, meds_piv, on='subject_id', how='left')\n",
    "    ### Fill missing values\n",
    "    days_cols = [col for col in demo_data.columns if 'dsf' in col or 'dsl' in col]\n",
    "    demo_data[days_cols] = demo_data[days_cols].fillna(9999).astype(np.int16)\n",
    "    nums_cols = [col for col in demo_data.columns if 'n_presc' in col]\n",
    "    demo_data[nums_cols] = demo_data[nums_cols].fillna(0).astype(np.int16)\n",
    "    demo_data['total_n_presc'] = demo_data['total_n_presc'].fillna(0).astype(np.int8)\n",
    "    return demo_data\n",
    "\n",
    "def prepare_admin_features(poe, demo_data):\n",
    "    #### Pivot table and create drug-specific features\n",
    "    def rename(col):\n",
    "        if isinstance(col, tuple):\n",
    "            col = '_'.join(str(c) for c in col)\n",
    "        return col\n",
    "    print('Getting administration features')\n",
    "    poe = poe[poe.subject_id.isin(demo_data.subject_id)]\n",
    "    poe['ordertime'] = pd.to_datetime(poe['ordertime'])\n",
    "    poe = poe.sort_values(['subject_id', 'ordertime'])\n",
    "    demo_poe = pd.merge(demo_data, poe[['subject_id', 'ordertime', 'order_type']], on='subject_id', how='left')\n",
    "    demo_poe = demo_poe[demo_poe['ordertime'] <= demo_poe['edregtime']]\n",
    "    ### Filter order types of interest (can be extended to capture specific treatments)\n",
    "    demo_poe = demo_poe[demo_poe.order_type.isin(['Nutrition', 'TPN', 'Cardiology', 'Radiology', 'Neurology', 'Respiratory', 'Hemodialysis'])]\n",
    "    poe_ids = demo_poe.groupby(['subject_id', 'order_type']).size().reset_index(name='admin_proc_count')\n",
    "    poe_piv = poe_ids.set_index(['subject_id', 'order_type']).unstack()\n",
    "    poe_piv.columns = map(rename, poe_piv)\n",
    "    poe_piv = poe_piv.reset_index()\n",
    "    poe_piv_total = poe_ids.groupby(['subject_id'])['order_type'].nunique().reset_index(name='total_proc_count')\n",
    "    demo_data = pd.merge(demo_data, poe_piv_total, on='subject_id', how='left')\n",
    "    demo_data = pd.merge(demo_data, poe_piv, on='subject_id', how='left')\n",
    "    ### Fill missing values\n",
    "    nums_cols = [col for col in demo_data.columns if 'proc_count' in col]\n",
    "    demo_data[nums_cols] = demo_data[nums_cols].fillna(0).astype(np.int16)\n",
    "    return demo_data\n",
    "\n",
    "def prepare_vitals(measures, ed_vitals, demo_data, output_path,\n",
    "                   vitalsign_column_map = {\n",
    "            \"temperature\": \"Temperature\",\n",
    "            \"heartrate\": \"Heart rate\",\n",
    "            \"resprate\": \"Respiratory rate\",\n",
    "            \"o2sat\": \"Oxygen saturation\",\n",
    "            \"sbp\": \"Systolic blood pressure\",\n",
    "            \"dbp\": \"Diastolic blood pressure\"},\n",
    "            vitalsign_uom_map = {\n",
    "            \"Temperature\": \"°F\",\n",
    "            \"Heart rate\": \"bpm\",\n",
    "            \"Respiratory rate\": \"insp/min\",\n",
    "            \"Oxygen saturation\": \"%\",\n",
    "            \"Systolic blood pressure\": \"mmHg\",\n",
    "            \"Diastolic blood pressure\": \"mmHg\",\n",
    "            \"BMI\": \"kg/m²\"\n",
    "        }):\n",
    "    print('Getting time-series data for vitals')\n",
    "    measures = measures[measures.subject_id.isin(demo_data.subject_id)]\n",
    "    ed_vitals = ed_vitals[ed_vitals.subject_id.isin(demo_data.subject_id)]\n",
    "    measures['chartdate'] = pd.to_datetime(measures['chartdate'] + ' ' + '00:00:00')\n",
    "    measures = measures.rename(columns={'chartdate': 'charttime'})\n",
    "    ed_vitals['charttime'] = pd.to_datetime(ed_vitals['charttime'])\n",
    "    ed_vitals = ed_vitals.drop(['stay_id', 'pain', 'rhythm'], axis=1)\n",
    "    measures = measures.drop(['seq_num'], axis=1)\n",
    "    ### Prepare ed vitals time-series\n",
    "    print('Preparing ED vitals for time-series data')\n",
    "    ed_vitals = ed_vitals.merge(demo_data[['subject_id', 'edregtime']], on='subject_id', how='left')\n",
    "    ed_vitals = ed_vitals[ed_vitals.charttime <= ed_vitals.edregtime]\n",
    "    ed_vitals = ed_vitals.drop(['edregtime'], axis=1)\n",
    "    ed_vitals = ed_vitals.rename(columns=vitalsign_column_map)\n",
    "    ed_vitals = ed_vitals.melt(id_vars=['subject_id', 'charttime'], value_vars=[\n",
    "                \"Temperature\",\n",
    "                \"Heart rate\",\n",
    "                \"Respiratory rate\",\n",
    "                \"Oxygen saturation\",\n",
    "                \"Systolic blood pressure\",\n",
    "                \"Diastolic blood pressure\",\n",
    "            ],\n",
    "            var_name=\"label\", value_name='value').sort_values(['subject_id', 'charttime'])\n",
    "    ed_vitals['value'] = pd.to_numeric(ed_vitals['value'], errors='coerce')\n",
    "    ed_vitals = ed_vitals.dropna(subset=['value'])\n",
    "    ed_vitals['value_uom'] = ed_vitals['label'].map(vitalsign_uom_map)\n",
    "\n",
    "    ### Prepare hospital measures time-series\n",
    "    print('Preparing hospital measures for time-series data')\n",
    "    measures = measures.merge(demo_data[['subject_id', 'edregtime']], on='subject_id', how='left')\n",
    "    measures = measures[measures.charttime <= measures.edregtime]\n",
    "    measures = measures.drop(['edregtime'], axis=1)\n",
    "    measures['result_name'] = np.where(measures['result_name'].str.contains('Blood Pressure'), 'bp', measures['result_name'])\n",
    "    measures[['result_sysbp', 'result_diabp']] = measures['result_value'].str.split('/', expand=True)\n",
    "    measures['result_sysbp'] = pd.to_numeric(measures['result_sysbp'], errors='coerce')\n",
    "    measures['result_diabp'] = pd.to_numeric(measures['result_diabp'], errors='coerce')\n",
    "    measures['result_name'] = np.where(measures['result_name'].str.contains('BMI'), 'bmi', measures['result_name'])\n",
    "    \n",
    "    # Create separate rows for sysbp and diabp\n",
    "    sysbp_measures = measures[['subject_id', 'charttime', 'result_sysbp']].rename(columns={'result_sysbp': 'value'})\n",
    "    sysbp_measures['label'] = 'Systolic blood pressure'\n",
    "    diabp_measures = measures[['subject_id', 'charttime', 'result_diabp']].rename(columns={'result_diabp': 'value'})\n",
    "    diabp_measures['label'] = 'Diastolic blood pressure'\n",
    "\n",
    "    # Concatenate the sysbp and diabp measures\n",
    "    bp_measures = pd.concat([sysbp_measures, diabp_measures], axis=0)\n",
    "    # Add BMI measurements\n",
    "    bmi_measures = measures[measures['result_name'] == 'bmi'][['subject_id', 'charttime', 'result_value']].rename(columns={'result_value': 'value'})\n",
    "    bmi_measures['label'] = 'BMI'\n",
    "    measures = pd.concat([bp_measures, bmi_measures], axis=0)\n",
    "\n",
    "    # Map the value_uom\n",
    "    measures['value_uom'] = measures['label'].map(vitalsign_uom_map)\n",
    "\n",
    "    # Combine with ed_vitals\n",
    "    vitals = pd.concat([ed_vitals, measures], axis=0)\n",
    "    vitals['linksto'] = 'vitals_measurements'\n",
    "    vitals['value'] = pd.to_numeric(vitals['value'], errors='coerce')\n",
    "    vitals = vitals.dropna(subset=['value'])\n",
    "    # Drop any duplicate entries\n",
    "    vitals = vitals.sort_values(['subject_id', 'charttime']).drop_duplicates(['subject_id', 'charttime', 'label'], keep='last')\n",
    "    vitals.to_csv(output_path, index=False)\n",
    "    return vitals\n",
    "\n",
    "def get_generic_drugs(df, prod_table_path):\n",
    "    \"\"\"Takes NDC product table and prescriptions dataframe; adds column with NDC table's corresponding generic name\"\"\"\n",
    "    mapping = pd.read_csv(prod_table_path, encoding='latin1')\n",
    "    mapping['PRODUCTNDC'] = mapping['PRODUCTNDC'].apply(lambda x: '-'.join(x.split('-')[:2]))\n",
    "    ndc_to_generic = mapping.set_index('PRODUCTNDC')['NONPROPRIETARYNAME'].to_dict()\n",
    "    \n",
    "    def brand_to_generic(ndc):\n",
    "        matches = list(re.finditer(r\"-\", ndc))\n",
    "        if len(matches) > 1:\n",
    "            ndc = ndc[:matches[1].start()]\n",
    "        return ndc_to_generic.get(ndc, np.nan)\n",
    "    \n",
    "    tqdm.pandas()\n",
    "    df['generic_drug_name'] = df['ndc'].progress_apply(brand_to_generic)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_data = read_prescriptions_table(core_path, demo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat = prepare_prescription_features(meds_data, demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.total_n_presc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in meds_feat.columns.tolist():\n",
    "    if 'dsl' in col:\n",
    "        print(meds_feat[col].value_counts().head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.to_csv('../outputs/linked_data/linked_meds_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat = pd.read_csv('../outputs/linked_data/linked_meds_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_test = dataframe_from_csv(os.path.join(core_path, 'hosp/poe.csv.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specialty-related orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat = prepare_admin_features(poe_test, meds_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.to_csv('../outputs/linked_data/linked_meds_proc_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in meds_feat.columns.tolist():\n",
    "    if 'admin' in col:\n",
    "        print(meds_feat[col].value_counts().head())\n",
    "        print(meds_feat[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get vital signs and lab tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_test = dataframe_from_csv(os.path.join(core_path, 'hosp/omr.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_test = dataframe_from_csv(os.path.join(ed_path, 'ed/vitalsign.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_test.result_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_data = prepare_vitals(measures_test, vitals_test, meds_feat, '../outputs/linked_data/measures_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measure_data.shape, measure_data.subject_id.nunique())\n",
    "print(measure_data[measure_data.label.str.contains('blood pressure')].shape,\n",
    "    measure_data[measure_data.label.str.contains('blood pressure')].subject_id.nunique())\n",
    "print(measure_data[measure_data.label.str.contains('BMI')].shape,\n",
    "    measure_data[measure_data.label.str.contains('BMI')].subject_id.nunique())\n",
    "print(measure_data[measure_data.label.str.contains('Temperature')].shape,\n",
    "    measure_data[measure_data.label.str.contains('Temperature')].subject_id.nunique())\n",
    "print(measure_data[measure_data.label.str.contains('Respiratory rate')].shape,\n",
    "    measure_data[measure_data.label.str.contains('Respiratory rate')].subject_id.nunique())\n",
    "print(measure_data[measure_data.label.str.contains('Oxygen saturation')].shape,\n",
    "    measure_data[measure_data.label.str.contains('Oxygen saturation')].subject_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Blood tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = pd.read_csv('../outputs/linked_data/linked_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get most common lab tests as reference data\n",
    "labs_lkup = pd.read_csv(os.path.join(core_path, 'hosp/labevents.csv'),\n",
    "                        chunksize=10000000, low_memory=False)\n",
    "labs_names = pd.read_csv(os.path.join(core_path, 'hosp/d_labitems.csv.gz'), compression='gzip')\n",
    "labs_names = labs_names[['itemid', 'label']]\n",
    "labs_lkup = pd.merge(labs_lkup.get_chunk(10000000), labs_names, on='itemid', how='left')\n",
    "labs_lkup = labs_lkup.dropna(subset=['itemid', 'label', 'valuenum', 'valueuom'])\n",
    "labs_lkup['label'] = labs_lkup['label'].str.lower().str.strip().str.replace(' ', '_').str.replace(',', '').str.replace('\"', '')\n",
    "labs_lkup = labs_lkup[['subject_id', 'itemid', 'label']].groupby(['itemid', 'label']).size().reset_index(name='n_tests')\n",
    "labs_lkup = labs_lkup.sort_values(['n_tests'], ascending=False).head(50)\n",
    "labs_lkup.to_csv('../outputs/linked_data/labs_lkup.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_lkup = pd.read_csv(os.path.join(core_path, 'hosp/labevents.csv'),\n",
    "                        chunksize=10000, low_memory=False)\n",
    "labs_lkup.get_chunk(10).charttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export lab test ids as txt\n",
    "lab_items_new = labs_lkup.itemid.tolist()\n",
    "with open('../outputs/linked_data/lab_items.txt', 'w') as f:\n",
    "    for item in lab_items_new:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_data = pl.scan_csv(os.path.join(core_path, 'hosp/labevents.csv'), try_parse_dates=True)\n",
    "d_items = (pl.read_csv(os.path.join(core_path, \"hosp/d_labitems.csv.gz\")).lazy().select([\"itemid\", \"label\"]))\n",
    "# merge labitem id's with dict\n",
    "labs_data = labs_data.join(d_items, how='left', on=\"itemid\")\n",
    "# select relevant columns\n",
    "labs_data = (labs_data.select([\"subject_id\", \"charttime\", \"itemid\", \"label\", \"value\", \"valueuom\"])\n",
    "        .with_columns(charttime=pl.col(\"charttime\").cast(pl.Datetime), linksto=pl.lit(\"labevents\")))\n",
    "# get eligible lab tests prior to current episode\n",
    "labs_data = labs_data.join(pl.from_pandas(demo_data[['subject_id', 'edregtime']]).lazy().\n",
    "                           with_columns(edregtime=pl.col(\"edregtime\").str.to_datetime(format=\"%Y-%m-%d %H:%M:%S\")), \n",
    "                           how='left', on=\"subject_id\")\n",
    "labs_data = labs_data.filter(pl.col(\"charttime\") <= pl.col(\"edregtime\")).drop([\"edregtime\"])\n",
    "# get most common items\n",
    "labs_data = labs_data.filter(pl.col(\"itemid\").is_in(set(lab_items_new)))\n",
    "labs_data = labs_data.with_columns(\n",
    "    pl.col(\"label\").str.to_lowercase().str.replace(\" \", \"_\").str.replace(\",\", \"\").str.replace('\"', \"\").str.replace(\" \", \"_\"),\n",
    "    pl.col(\"charttime\").str.replace(\"T\", \" \").str.strip_chars()\n",
    ")\n",
    "lab_events = labs_data.with_columns(\n",
    "        value=pl.when(pl.col(\"value\") == \".\").then(None).otherwise(pl.col(\"value\"))\n",
    ")\n",
    "lab_events = lab_events.with_columns(\n",
    "    value=pl.when(pl.col(\"value\").str.contains(\"_|<|ERROR\"))\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"value\"))\n",
    "    .cast(pl.Float64, strict=False)  # Attempt to cast to Float64, set invalid values to None\n",
    ")\n",
    "labs_data = labs_data.drop_nulls()\n",
    "\n",
    "# Remove outliers using 2 std from mean\n",
    "lab_events = lab_events.with_columns(mean=pl.col(\"value\").mean().over(pl.count(\"label\")))\n",
    "lab_events = lab_events.with_columns(std=pl.col(\"value\").std().over(pl.count(\"label\")))\n",
    "lab_events = lab_events.filter(\n",
    "    (pl.col(\"value\") < pl.col(\"mean\") + pl.col(\"std\") * 2)\n",
    "    & (pl.col(\"value\") > pl.col(\"mean\") - pl.col(\"std\") * 2)\n",
    ").drop([\"mean\", \"std\"])\n",
    "\n",
    "lab_events = lab_events.collect()\n",
    "lab_events.write_csv(include_header=True, file='../outputs/linked_data/labs_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_test = pd.read_csv('../outputs/linked_data/labs_ts.csv', chunksize=10)\n",
    "labs_test.get_chunk(10).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labs_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_data.limit(10000).collect().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
